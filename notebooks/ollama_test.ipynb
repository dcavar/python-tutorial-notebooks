{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15126626",
   "metadata": {},
   "source": [
    "# Testing Ollama Communication\n",
    "\n",
    "&copy; 2025 by [Damir Cavar](https://damir.cavar.me/)\n",
    "\n",
    "This is an example about how to interacte with an [Ollama server](https://ollama.com/) and a loaded model.\n",
    "\n",
    "**Version:** 1.0, September 2025\n",
    "\n",
    "**Download:** This and various other Jupyter notebooks are available from my [GitHub repo](https://github.com/dcavar/python-tutorial-for-ipython).\n",
    "\n",
    "This is a tutorial related to the L715 seminar on Large Language Models and Semantic RAGs, Ontologies, and Reasoning with Agentive AI models.\n",
    "\n",
    "Install the [Ollama server](https://ollama.com/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a0455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eab6db",
   "metadata": {},
   "source": [
    "Install a model, e.g., `Llama3` in the command line on Linux:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fc181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull llama3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e19d2d",
   "metadata": {},
   "source": [
    "Open [Ollama](https://ollama.com/) in Windows you might need to log into your [Ollama](https://ollama.com/) account. You might need to expose [Ollama](https://ollama.com/) to the network in settings. Consider setting the context lenght as your computer allows it. In Windows you might have to start a new PowerShell or CMD to activate the binary path and use `ollama` via command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b076e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fb77f1",
   "metadata": {},
   "source": [
    "Submit a prompt to the endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93754370",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama.generate(model='llama3', prompt='What is a long-distance passive construction?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fc8a288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A fascinating topic in linguistics!\n",
      "\n",
      "In linguistics, a long-distance passive construction (LDPC) refers to a specific type of sentence structure where the subject of the main clause is not the same as the subject of a subordinate clause that contains a passive verb phrase. In other words, there is a gap or distance between the agent of the action described by the subordinate clause and its grammatical subject.\n",
      "\n",
      "To illustrate this, consider the following example:\n",
      "\n",
      "**Main clause:** The new policy was implemented yesterday.\n",
      "**Subordinate clause:** It was designed by a team of experts.\n",
      "\n",
      "In this sentence, \"it\" is not the same as \"a team of experts,\" which would be the agent performing the action described in the subordinate clause (\"designed\"). Instead, \"it\" is the subject of the main clause, while \"the new policy\" is the object. This creates a long distance between the agent (the team) and its grammatical subject (the policy).\n",
      "\n",
      "LDPCs are interesting because they can reveal important information about the relationships between clauses in a sentence, as well as the speakers' intentions and preferences for word order. They have been studied extensively in various languages, including English, Chinese, Japanese, and others.\n",
      "\n",
      "Do you have any specific questions or would you like more examples?\n"
     ]
    }
   ],
   "source": [
    "print(response['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17d5f259",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "        {'role': 'user', 'content': 'What is the capital of France?'},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "656ccea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "chat_response = ollama.chat(model='llama3', messages=messages)\n",
    "print(chat_response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfeed8c",
   "metadata": {},
   "source": [
    "It will not remember this way the most recent question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc3bc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "        {'role': 'user', 'content': 'What do you recommend me to go and see there?'},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c10875",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_response = ollama.chat(model='llama3', messages=messages)\n",
    "print(chat_response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7245b54",
   "metadata": {},
   "source": [
    "**&copy; 2025 by [Damir Cavar](http://damir.cavar.me/) <<dcavar@iu.edu>>**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
