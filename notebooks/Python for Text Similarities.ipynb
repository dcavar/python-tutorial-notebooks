{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for Text Similarities 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(C) 2017-2023 by [Damir Cavar](http://damir.cavar.me/)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download:** This and various other Jupyter notebooks are available from my [GitHub repo](https://github.com/dcavar/python-tutorial-notebooks)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Version:** 1.3, January 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**License:** [Creative Commons Attribution-ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/) ([CA BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a tutorial related to the discussion of text similarities in the textbook [Machine Learning: The Art and Science of Algorithms that Make Sense of Data](https://www.cs.bris.ac.uk/~flach/mlbook/) by [Peter Flach](https://www.cs.bris.ac.uk/~flach/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial was developed as part of my course material for the course Machine Learning for Computational Linguistics in the [Computational Linguistics Program](http://cl.indiana.edu/) of the [Department of Linguistics](http://www.indiana.edu/~lingdept/) at [Indiana University](https://www.indiana.edu/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "The following code examples presuppose a running [Python 3.x](https://python.org/) environment with [Jupyter Lab](https://jupyter.org/) and [NLTK](https://www.nltk.org/) installed.\n",
    "\n",
    "For [NLTK](https://www.nltk.org/) installation, follow the instructions on the [NLTK Documentation](https://www.nltk.org/data.html) page. You will also need to install the data packages required by the example code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the Jaccard coefficient we prepare two texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"\"\"Our medicine cures baldness. No diagnostics needed.\n",
    "           We guarantee Fast Viagra delivery.\n",
    "           We can provide Human growth hormone. The cheapest Life\n",
    "           Insurance with us. You can Lose weight with this treatment.\n",
    "           Our Medicine now and No medical exams necessary.\n",
    "           Our Online pharmacy is the best.  This cream Removes\n",
    "           wrinkles and Reverses aging.\n",
    "           One treatment and you will Stop snoring.  We sell Valium\n",
    "           and Viagra.\n",
    "           Our Vicodin will help with Weight loss. Cheap Xanax.\"\"\"\n",
    "text2 = \"\"\"Dear ,\n",
    "           we sell the cheapest and best Viagra on the planet. Our delivery is\n",
    "           guaranteed confident and cheap.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the *word_tokenizer* from the [NLTK](https://www.nltk.org/) module. We convert the tokenlist from each text to a set of types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "types1 = set(word_tokenize(text1))\n",
    "types2 = set(word_tokenize(text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The types in the first text are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wrinkles', 'medicine', 'exams', 'necessary', 'This', 'Reverses', 'cheapest', 'the', 'pharmacy', 'weight', 'growth', 'cures', 'will', 'Xanax', 'You', 'The', 'Vicodin', 'with', 'needed', 'Life', 'now', 'and', 'Medicine', 'Human', 'loss', 'us', 'you', 'Valium', 'cream', 'aging', 'sell', 'Lose', 'treatment', 'help', 'snoring', 'baldness', 'hormone', 'delivery', 'can', 'Our', 'guarantee', 'Insurance', 'Removes', 'best', 'Fast', 'Cheap', 'diagnostics', 'We', 'medical', 'One', 'No', 'Online', 'this', 'Weight', 'provide', '.', 'Viagra', 'is', 'Stop'}\n"
     ]
    }
   ],
   "source": [
    "print(types1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate the instersection from the two sets of types in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best', 'sell', 'and', 'cheapest', 'the', 'delivery', '.', 'Viagra', 'is', 'Our'}\n"
     ]
    }
   ],
   "source": [
    "print(set.intersection(types1, types2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the Jaccard coefficient we divide the length of the intersection of the sets of types by the length of the union of these sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14925373134328357\n"
     ]
    }
   ],
   "source": [
    "lenIntersect = len(set.intersection(types1, types2))\n",
    "lenUnion = len(set.union(types1, types2))\n",
    "\n",
    "print(lenIntersect / lenUnion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This division is equivalent to the division of $\\frac{words\\,in\\,both\\,sets}{(words\\,in\\,set\\,1)\\,+\\,(words\\,in\\,set\\,2)\\,-\\,(words\\,in\\,both\\,sets)}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(C) 2017-2023 by [Damir Cavar](http://cavar.me/damir/) - [Creative Commons Attribution-ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/) ([CA BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "latex_metadata": {
   "affiliation": "Indiana University, Department of Linguistics, Bloomington, IN, USA",
   "author": "Damir Cavar",
   "title": "Python for Text Similarities"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "1e28a5307a9b5c2fbeb0b263581f1cf3bfba9739188743f6a231f74c7de58892"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
