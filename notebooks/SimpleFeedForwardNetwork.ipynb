{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Simple Feed Forward Neural Network from Scratch - Part 1\n",
    "\n",
    "© 2023-2025 by [Damir Cavar](http://damir.cavar.me/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prerequisites:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U numpy\n",
    "!pip install -U nltk\n",
    "!pip install -U scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([2, 3, 4, 5, 6, 7])\n",
    "num_features = 5\n",
    "W = np.random.rand(len(x), num_features)\n",
    "b = np.random.rand(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 4 5 6 7]]\n",
      "[[2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]]\n"
     ]
    }
   ],
   "source": [
    "x_reshaped = x.reshape(len(x), 1)\n",
    "print(x_reshaped.T)\n",
    "print(x_reshaped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8619727 , 0.58781623, 0.08192724, 0.32024874, 0.37586709],\n",
       "       [0.53599043, 0.65137649, 0.26528275, 0.95910965, 0.25807033],\n",
       "       [0.59982028, 0.05620878, 0.39362914, 0.35532813, 0.46986993],\n",
       "       [0.91292256, 0.80483918, 0.86397291, 0.685994  , 0.34818464],\n",
       "       [0.53730966, 0.10045434, 0.69879575, 0.67768112, 0.96681444],\n",
       "       [0.03872422, 0.76156201, 0.75984532, 0.6103069 , 0.43399413]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98591156, 0.20060554, 0.71763632, 0.70060456, 0.07488563])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x_reshaped.T @ W + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14.7766497  13.51305862 17.08341187 17.40794855 14.06007926]]\n"
     ]
    }
   ],
   "source": [
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0.0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.7766497 , 13.51305862, 17.08341187, 17.40794855, 14.06007926]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = relu(z)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = np.random.rand(len(a[0]), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.62690381],\n",
       "       [0.35202677],\n",
       "       [0.69657002],\n",
       "       [0.70607078],\n",
       "       [0.27014452]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8360188  0.11314284 0.05083836]]\n",
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "print(softmax(np.array([[3.0, 1.0, 0.2]])))\n",
    "print(sum(softmax(np.array([[30.0, 10.0, 2.0]]))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42.0097863]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "z2 = a @ U\n",
    "print(z2)\n",
    "sigmoid(z2[0][0])\n",
    "print(sigmoid(z2.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Reviews corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_data = []\n",
    "with open(os.path.join('.', 'data', 'reviews.csv'), newline='') as csvfile:\n",
    "    datareader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    header = next(datareader)\n",
    "    for row in datareader:\n",
    "        if len(row) == 2:\n",
    "            experiment_data.append( [row[0].strip(), int(row[1].strip())] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrific sea rescue sequences, of which there are very few I just did not care about any of the characters. Most of us have ghosts in the closet, and Costner's character are realized early on, and then forgotten until much later, by which time I did not care. The character we should really care about is a very cocky, overconfident Ashton Kutcher. The problem is he comes off as kid who thinks he's better than anyone else around him and shows no signs of a cluttered closet. His only obstacle appears to be winning over Costner. Finally when we are well past the half way point of this stinker, Costner tells us all about Kutcher's ghosts. We are told why Kutcher is driven to be the best with no prior inkling or foreshadowing. No magic here, it was all I could do to keep from turning it off an hour in.\", 0], [\"This is an example of why the majority of action films are the same. Generic and boring, there's really nothing worth watching here. A complete waste of the then barely-tapped talents of Ice-T and Ice Cube, who've each proven many times over that they are capable of acting, and acting well. Don't bother with this one, go see New Jack City, Ricochet or watch New York Undercover for Ice-T, or Boyz n the Hood, Higher Learning or Friday for Ice Cube and see the real deal. Ice-T's horribly cliched dialogue alone makes this film grate at the teeth, and I'm still wondering what the heck Bill Paxton was doing in this film? And why the heck does he always play the exact same character? From Aliens onward, every film I've seen with Bill Paxton has him playing the exact same irritating character, and at least in Aliens his character died, which made it somewhat gratifying... Overall, this is second-rate action trash. There are countless better films to see, and if you really want to see this one, watch Judgement Night, which is practically a carbon copy but has better acting and a better script. The only thing that made this at all worth watching was a decent hand on the camera - the cinematography was almost refreshing, which comes close to making up for the horrible film itself - but not quite. 4/10.\", 0]]\n",
      "Text:\n",
      " Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrific sea rescue sequences, of which there are very few I just did not care about any of the characters. Most of us have ghosts in the closet, and Costner's character are realized early on, and then forgotten until much later, by which time I did not care. The character we should really care about is a very cocky, overconfident Ashton Kutcher. The problem is he comes off as kid who thinks he's better than anyone else around him and shows no signs of a cluttered closet. His only obstacle appears to be winning over Costner. Finally when we are well past the half way point of this stinker, Costner tells us all about Kutcher's ghosts. We are told why Kutcher is driven to be the best with no prior inkling or foreshadowing. No magic here, it was all I could do to keep from turning it off an hour in.\n",
      "Value:\n",
      " 0\n",
      "Number of records: 50000\n"
     ]
    }
   ],
   "source": [
    "print(experiment_data[:2])\n",
    "print(\"Text:\\n\", experiment_data[0][0])\n",
    "print(\"Value:\\n\", experiment_data[0][1])\n",
    "print(\"Number of records:\", len(experiment_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Vader lexicon for lexical sentiment analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_dictionary = {}\n",
    "with open(os.path.join('.', 'data', 'vader_lexicon.txt'), mode='r', encoding='utf-8') as ifile:\n",
    "    lines = ifile.readlines()\n",
    "    sentiment_dictionary = { y[0]: y[1] for y in [ x.split('\\t') for x in lines ] if len(y) == 4 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_dictionary[\"adventurer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the set of 1st and 2nd person pronouns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronouns = {\"i\", \"me\", \"my\", \"mine\", \"you\", \"yours\", \"yourself\", \"myself\", \"we\", \"us\", \"our\", \"ours\", \"ourselves\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vectorization function for the review texts is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer(text: str) -> list:\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    scores = [ float(sentiment_dictionary.get(t, 0.0)) for t in tokens ]\n",
    "    positive = len([ s for s in scores if s > 0 ])\n",
    "    negative = len([ s for s in scores if s < 0 ])\n",
    "    if \"no\" in tokens:\n",
    "        no_present = 1\n",
    "    else:\n",
    "        no_present = 0\n",
    "    counts = Counter(tokens)\n",
    "    pronoun_count = 0\n",
    "    for x in set(counts.keys()).intersection(pronouns):\n",
    "        pronoun_count += counts[x]\n",
    "    if \"!\" in tokens:\n",
    "        exclamation = 1\n",
    "    else:\n",
    "        exclamation = 0\n",
    "    return [positive, negative, no_present, pronoun_count, exclamation, math.log(len(tokens))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the vectors for all the corpus texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [ np.array(vectorizer(e[0])) for e in experiment_data ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 6\n",
      "[13.          8.          0.          3.          0.          5.58349631] \n",
      " [\"This is an example of why the majority of action films are the same. Generic and boring, there's really nothing worth watching here. A complete waste of the then barely-tapped talents of Ice-T and Ice Cube, who've each proven many times over that they are capable of acting, and acting well. Don't bother with this one, go see New Jack City, Ricochet or watch New York Undercover for Ice-T, or Boyz n the Hood, Higher Learning or Friday for Ice Cube and see the real deal. Ice-T's horribly cliched dialogue alone makes this film grate at the teeth, and I'm still wondering what the heck Bill Paxton was doing in this film? And why the heck does he always play the exact same character? From Aliens onward, every film I've seen with Bill Paxton has him playing the exact same irritating character, and at least in Aliens his character died, which made it somewhat gratifying... Overall, this is second-rate action trash. There are countless better films to see, and if you really want to see this one, watch Judgement Night, which is practically a carbon copy but has better acting and a better script. The only thing that made this at all worth watching was a decent hand on the camera - the cinematography was almost refreshing, which comes close to making up for the horrible film itself - but not quite. 4/10.\", 0] \n",
      " This is an example of why the majority of action films are the same. Generic and boring, there's really nothing worth watching here. A complete waste of the then barely-tapped talents of Ice-T and Ice Cube, who've each proven many times over that they are capable of acting, and acting well. Don't bother with this one, go see New Jack City, Ricochet or watch New York Undercover for Ice-T, or Boyz n the Hood, Higher Learning or Friday for Ice Cube and see the real deal. Ice-T's horribly cliched dialogue alone makes this film grate at the teeth, and I'm still wondering what the heck Bill Paxton was doing in this film? And why the heck does he always play the exact same character? From Aliens onward, every film I've seen with Bill Paxton has him playing the exact same irritating character, and at least in Aliens his character died, which made it somewhat gratifying... Overall, this is second-rate action trash. There are countless better films to see, and if you really want to see this one, watch Judgement Night, which is practically a carbon copy but has better acting and a better script. The only thing that made this at all worth watching was a decent hand on the camera - the cinematography was almost refreshing, which comes close to making up for the horrible film itself - but not quite. 4/10. \n",
      " 0\n",
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(len(x), len(x[0]))\n",
    "print(x[1], \"\\n\", experiment_data[1], \"\\n\", experiment_data[1][0], \"\\n\", experiment_data[1][1])\n",
    "y = np.array([ float(e[1]) for e in experiment_data ])\n",
    "print(y)\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.          9.          1.          8.          0.          5.23110862]\n",
      " [13.          8.          0.          3.          0.          5.58349631]\n",
      " [ 6.         14.          1.          5.          0.          5.49306144]\n",
      " ...\n",
      " [22.         18.          0.         12.          0.          6.14632926]\n",
      " [11.          0.          0.         12.          0.          5.32300998]\n",
      " [11.          7.          1.          1.          1.          5.27299956]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array(x)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the RelU activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0.0, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the variables and weights for the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.         9.         1.         8.         0.         5.23110862]\n",
      "W:\n",
      " [[0.15712481 0.71373242 0.43670908 0.92744404 0.8657041  0.67280756]\n",
      " [0.04211492 0.48538567 0.70691137 0.13823402 0.06752036 0.31788857]\n",
      " [0.33065637 0.17537358 0.15559781 0.30787449 0.9475915  0.78308026]]\n",
      "b:\n",
      " [0.51426813 0.22715494 0.78433198]\n",
      "W+b:\n",
      " [19.72777397  8.45035339 12.05357319]\n"
     ]
    }
   ],
   "source": [
    "print(x[0])\n",
    "num_features = len(x[0])\n",
    "num_rows = 3\n",
    "W = np.random.rand(num_rows, num_features)\n",
    "print(\"W:\\n\", W)\n",
    "b = np.random.rand(num_rows)\n",
    "print(\"b:\\n\", b)\n",
    "print(\"W+b:\\n\", relu(W @ x[0] + b) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output layer receives a *num-rows*-dimentional vector and generates one output z-score. Initialize the output layer of the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U:\n",
      " [[0.34349942 0.37909158 0.55288836]]\n",
      "bu:\n",
      " [0.6822026]\n",
      "[19.72777397  8.45035339 12.05357319]\n",
      "[0.99999997]\n"
     ]
    }
   ],
   "source": [
    "U = np.random.rand(1, num_rows)\n",
    "print(\"U:\\n\", U)\n",
    "bu = np.random.rand(1)\n",
    "print(\"bu:\\n\", bu)\n",
    "test = W @ x[0] + b\n",
    "print(test)\n",
    "print(sigmoid(U @ test + bu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data set in the following code is the entire data set. As an exercise use some function to randomly select a portion for training and another portion for testing. Use only the true randomly selected training data set for the following code. This code will run a complete inferencing cycle through the training data set, which is in this case the entire data set. Change the code and set up a real evaluation of training and testing, and computing of the F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for input_vector, truth in zip(x, y):\n",
    "    z = (W @ input_vector) + b\n",
    "    #print(\"z:\\n\", z)\n",
    "    a = relu(z)\n",
    "    #print(\"a:\\n\", a)\n",
    "    c = sigmoid((U @ a) + bu)\n",
    "    #print(\"c:\\n\", c)\n",
    "    results.append( (truth, c) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of results: 50000\n"
     ]
    }
   ],
   "source": [
    "print(\"# of results:\", len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positives: 25000\n",
      "True negatives: 0\n",
      "False positives: 25000\n",
      "False negatives: 0\n"
     ]
    }
   ],
   "source": [
    "counting_true_negatives = 0\n",
    "counting_true_positives = 0\n",
    "counting_false_positives = 0\n",
    "counting_false_negatives = 0\n",
    "for res in results:\n",
    "    # print(res[0], res[1][0])\n",
    "    if res[0] == 1:\n",
    "        if res[1][0] >= 0.5:\n",
    "            counting_true_positives += 1\n",
    "        else:\n",
    "            counting_false_negatives += 1\n",
    "    else:\n",
    "        if res[1][0] < 0.5:\n",
    "            counting_true_negatives += 1\n",
    "        else:\n",
    "            counting_false_positives += 1\n",
    "print(\"True positives:\", counting_true_positives)\n",
    "print(\"True negatives:\", counting_true_negatives)\n",
    "print(\"False positives:\", counting_false_positives)\n",
    "print(\"False negatives:\", counting_false_negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuation in *SimpleFeedForwardNetwork_2*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "© 2025 by [Damir Cavar](https://damir.cavar.me/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
