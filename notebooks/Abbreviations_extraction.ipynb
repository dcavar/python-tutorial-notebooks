{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acronym Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(C) 2022-2024 by [Damir Cavar](http://damir.cavar.me/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Version:** 0.3, September 2024\n",
    "\n",
    "**Download:** This and various other Jupyter notebooks are available from my [GitHub repo](https://github.com/dcavar/python-tutorial-for-ipython).\n",
    "\n",
    "**License:** [Creative Commons Attribution-ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/) ([CA BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of the use of the *[abbreviations](https://github.com/philgooch/abbreviation-extraction)* module to extract acronyms from documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the module using:\n",
    "\n",
    "    pip install abbreviations\n",
    "\n",
    "For the *FileChooser* widget in this Jupyter notebook you might need to install also the *[ipyfilechooser](https://github.com/crahan/ipyfilechooser)*:\n",
    "\n",
    "    pip install ipyfilechooser\n",
    "\n",
    "The code below assumes that the text is encoded as UTF-8. If this is not the case for you, adapt the encoding specification in the *get_abbreviation* function below or convert your text to use the UTF-8 character encoding."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T01:22:31.946493Z",
     "start_time": "2024-10-22T01:22:28.201737Z"
    }
   },
   "source": [
    "!pip install -U abbreviations"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting abbreviations\n",
      "  Using cached abbreviations-0.2.5-py3-none-any.whl.metadata (550 bytes)\n",
      "Collecting regex (from abbreviations)\n",
      "  Downloading regex-2024.9.11-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "     -------------------------------------- 41.5/41.5 kB 666.1 kB/s eta 0:00:00\n",
      "Using cached abbreviations-0.2.5-py3-none-any.whl (5.7 kB)\n",
      "Downloading regex-2024.9.11-cp312-cp312-win_amd64.whl (273 kB)\n",
      "   ---------------------------------------- 0.0/273.5 kB ? eta -:--:--\n",
      "   ---------------------------- ----------- 194.6/273.5 kB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 273.5/273.5 kB 4.2 MB/s eta 0:00:00\n",
      "Installing collected packages: regex, abbreviations\n",
      "Successfully installed abbreviations-0.2.5 regex-2024.9.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T01:22:37.385335Z",
     "start_time": "2024-10-22T01:22:32.737376Z"
    }
   },
   "source": [
    "!pip install -U ipyfilechooser"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipyfilechooser\n",
      "  Using cached ipyfilechooser-0.6.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting ipywidgets (from ipyfilechooser)\n",
      "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\damir\\dropbox\\work\\icatalyst-dev\\rcmt_nlppipeline\\venv\\lib\\site-packages (from ipywidgets->ipyfilechooser) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\damir\\dropbox\\work\\icatalyst-dev\\rcmt_nlppipeline\\venv\\lib\\site-packages (from ipywidgets->ipyfilechooser) (8.28.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\damir\\dropbox\\work\\icatalyst-dev\\rcmt_nlppipeline\\venv\\lib\\site-packages (from ipywidgets->ipyfilechooser) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.12 (from ipywidgets->ipyfilechooser)\n",
      "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.12 (from ipywidgets->ipyfilechooser)\n",
      "  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: decorator in c:\\users\\damir\\dropbox\\work\\icatalyst-dev\\rcmt_nlppipeline\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->ipyfilechooser) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\damir\\dropbox\\work\\icatalyst-dev\\rcmt_nlppipeline\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->ipyfilechooser) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\damir\\dropbox\\work\\icatalyst-dev\\rcmt_nlppipeline\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->ipyfilechooser) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\damir\\dropbox\\work\\icatalyst-dev\\rcmt_nlppipeline\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->ipyfilechooser) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\damir\\dropbox\\work\\icatalyst-dev\\rcmt_nlppipeline\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->ipyfilechooser) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\damir\\dropbox\\work\\icatalyst-dev\\rcmt_nlppipeline\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->ipyfilechooser) (0.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\damir\\dropbox\\work\\icatalyst-dev\\rcmt_nlppipeline\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->ipyfilechooser) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\damir\\dropbox\\work\\icatalyst-dev\\rcmt_nlppipeline\\venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->ipyfilechooser) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\damir\\dropbox\\work\\icatalyst-dev\\rcmt_nlppipeline\\venv\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->ipyfilechooser) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\damir\\dropbox\\work\\icatalyst-dev\\rcmt_nlppipeline\\venv\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets->ipyfilechooser) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\damir\\dropbox\\work\\icatalyst-dev\\rcmt_nlppipeline\\venv\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets->ipyfilechooser) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\damir\\dropbox\\work\\icatalyst-dev\\rcmt_nlppipeline\\venv\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets->ipyfilechooser) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\damir\\dropbox\\work\\icatalyst-dev\\rcmt_nlppipeline\\venv\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets->ipyfilechooser) (1.16.0)\n",
      "Using cached ipyfilechooser-0.6.0-py3-none-any.whl (11 kB)\n",
      "Downloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.8 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 81.9/139.8 kB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 139.8/139.8 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n",
      "   ---------------------------------------- 0.0/214.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 214.4/214.4 kB 12.8 MB/s eta 0:00:00\n",
      "Downloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.6/2.3 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.9/2.3 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.7/2.3 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 12.4 MB/s eta 0:00:00\n",
      "Installing collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets, ipyfilechooser\n",
      "Successfully installed ipyfilechooser-0.6.0 ipywidgets-8.1.5 jupyterlab-widgets-3.0.13 widgetsnbextension-4.0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to activate the *FileChooser* and select a folder with the target text files in it. The target text files can be in subfolders of arbitrary depth within this folder. A good example file is ```bio_1.txt``` in the ```data``` subfolder."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T01:25:29.555888Z",
     "start_time": "2024-10-22T01:25:29.416821Z"
    }
   },
   "source": [
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "fc = FileChooser()\n",
    "display(fc)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileChooser(path='C:\\Users\\damir\\Dropbox\\Develop\\python-tutorial-notebooks\\notebooks', filename='', title='', â€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b112aa15002645fe969fc3660956b010"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code cell we will import the necessary modules *[abbreviations](https://github.com/philgooch/abbreviation-extraction)* and *os* used in the functions below to process subfolders, find target text files, and extract all abbreviations from them."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T01:25:36.743927Z",
     "start_time": "2024-10-22T01:25:36.723644Z"
    }
   },
   "source": [
    "from abbreviations import schwartz_hearst\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function reads the content from a text file in the *folder_path* and *directory* subdirectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_abbreviations(file_name=\"\"):\n",
    "    if not os.path.exists(file_name):\n",
    "        return\n",
    "    print(\"Processing file:\", file_name)\n",
    "    try:\n",
    "        ifp = open(file_name, mode='r', encoding='utf-8')\n",
    "        text = ifp.read()\n",
    "        ifp.close()\n",
    "    except IOError:\n",
    "        return\n",
    "    if not text:\n",
    "        return\n",
    "    most_common_defs = schwartz_hearst.extract_abbreviation_definition_pairs(doc_text=text, most_common_definition=True)\n",
    "    first_defs = schwartz_hearst.extract_abbreviation_definition_pairs(doc_text=text, first_definition=True)\n",
    "    return most_common_defs, first_defs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the selected text file and print the resulting abbreviations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\damir\\Dropbox\\Develop\\python-tutorial-notebooks\\notebooks\\data\\bio_1.txt\n",
      "({'ER': 'endoplasmic reticulum'}, {'ER': 'endoplasmic reticulum'})\n"
     ]
    }
   ],
   "source": [
    "abbreviations = get_abbreviations(os.path.join(fc.selected_path, fc.selected_filename))\n",
    "print(abbreviations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri_prefix = \"http://www.indiana.edu/nlplab/bioterminology#\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib.namespace import RDF, RDFS, SKOS, OWL, DC, DCTERMS, XSD, TIME, NamespaceManager\n",
    "from rdflib import Graph, URIRef, Literal, Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {}\n",
    "for x in abbreviations:\n",
    "    entry = tuple(x.items())[0]\n",
    "    dictionary[uri_prefix + \"\".join([z.title() for z in entry[1].split()])] = entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "g = Graph()\n",
    "vaem_acronym = URIRef(\"http://www.linkedmodel.org/schema/vaem#acronym\")\n",
    "for key in dictionary:\n",
    "    g.add((URIRef(key), RDFS.label, Literal(dictionary[key][1])))\n",
    "    g.add((URIRef(key), vaem_acronym, Literal(dictionary[key][0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pytextrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pytextrank.base.BaseTextRankFactory at 0x22b2e203010>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_trf\")  # en_core_web_sm\")\n",
    "nlp.add_pipe(\"textrank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(fc.selected_path, fc.selected_filename), mode='r', encoding='utf-8') as ifp:\n",
    "    text = ifp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for phrase in doc._.phrases:\n",
    "    print(phrase.text)\n",
    "    print(phrase.rank, phrase.count)\n",
    "    print(phrase.chunks)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "dictionary = {}\n",
    "for x in doc._.phrases:\n",
    "    entry = x.text  # tuple(x.items())[0]\n",
    "    key = URIRef(uri_prefix + \"\".join([z.title() for z in entry.split()]))\n",
    "    # = entry\n",
    "    # for key in dictionary:\n",
    "    g.add((URIRef(key), RDFS.label, Literal(entry)))\n",
    "    # g.add( (URIRef(key), vaem_acronym, Literal(dictionary[key][0])) )\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "nelabels = {\"ORG\": \"Organization\",\n",
    "            \"PERSON\": \"Person\"}\n",
    "for k in nelabels:\n",
    "    g.add((URIRef(uri_prefix + nelabels[k]), RDF.type, OWL.Class))\n",
    "for ent in doc.ents:\n",
    "    # print(ent.text, ent.label_)\n",
    "    if ent.label_ in (\"ORG\", \"PERSON\"):\n",
    "        key = URIRef(uri_prefix + \"\".join([z.title() for z in ent.text.split()]))\n",
    "        type = nelabels[ent.label_]\n",
    "        g.add((key, RDF.type, URIRef(uri_prefix + type)))\n",
    "        g.add((key, RDFS.label, Literal(ent.text)))\n",
    "        # print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N8793d07f04814241b59925a0d5c3aeae (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.serialize(destination=\"data/test_graph.ttl\", format=\"turtle\", encoding=\"utf-8\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(C) 2022-2024 by [Damir Cavar](http://damir.cavar.me/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e28a5307a9b5c2fbeb0b263581f1cf3bfba9739188743f6a231f74c7de58892"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
