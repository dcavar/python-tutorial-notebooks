{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gram Models from Text for Language Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(C) 2024 by [Damir Cavar](http://damir.cavar.me/) <<dcavar@iu.edu>>**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Version:** 1.0, February 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download:** This and various other Jupyter notebooks are available from my [GitHub repo](https://github.com/dcavar/python-tutorial-notebooks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**License:** [Creative Commons Attribution-ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/) ([CA BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prerequisites:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple File Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make use of the following modules and functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading a text into memory in Python is faily simple. We open a file, read from it, and close the file again. The following code prints out the first 300 characters of the text in memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A HOUSE OF POMEGRANATES\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Contents:\n",
      "\n",
      "The Young King\n",
      "The Birthday of the Infanta\n",
      "The Fisherman and his Soul\n",
      "The Star-child\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE YOUNG KING\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[TO MARGARET LADY BROOKE--THE RANEE OF SARAWAK]\n",
      "\n",
      "\n",
      "It was the night before the day fixed for his coronation, and the\n",
      "young King was sitting alone in his b ...\n"
     ]
    }
   ],
   "source": [
    "ifile = open(\"data/HOPG.txt\", mode='r', encoding='utf-8')\n",
    "text = ifile.read()\n",
    "ifile.close()\n",
    "print(text[:300], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optional parameters in the *open* function above define the **mode** of operations on the file and the **encoding** of the content. For example, setting the **mode** to **r** declares that *reading* from the file is the only permitted operation that we will perform in the following code. Setting the **encoding** to **utf-8** declares that all characters will be encoded using the [Unicode](https://en.wikipedia.org/wiki/Unicode) encoding schema [UTF-8](https://en.wikipedia.org/wiki/UTF-8) for the content of the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now import the [NLTK](https://www.nltk.org/) module in Python to work with frequency profiles and [n-grams](https://en.wikipedia.org/wiki/N-gram) using the tokens or words in the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now lower the text, which means normalizing it to all characters lower case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a house of pomegranates\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contents:\n",
      "\n",
      "the young king\n",
      "the birthday of the infanta\n",
      "the fisherman and his soul\n",
      "the star-child\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "the young king\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[to margaret lady brooke--the ranee of sarawak]\n",
      "\n",
      "\n",
      "it was the night before the day fixed for his coronation, and the\n",
      "young king was sitting alone in his b ...\n"
     ]
    }
   ],
   "source": [
    "text = text.lower()\n",
    "print(text[:300], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the frequency profile is for the characters in the text, not the words or tokens. In order to generate a frequency profile over words/tokens in the text, we need to utilize a **tokenizer**. [NLTK](https://www.nltk.org/) provides basic tokenization functions. We will use the *word_tokenize* function to generate a list of tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now print the first 20 tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'house', 'of', 'pomegranates', 'contents', ':', 'the', 'young', 'king', 'the', 'birthday', 'of', 'the', 'infanta', 'the', 'fisherman', 'and', 'his', 'soul', 'the']\n"
     ]
    }
   ],
   "source": [
    "print(tokens[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a bigram model, we use the NLTK ngram model function and generate a bigram profile and relativize the frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTokenBigrams = nltk.ngrams(tokens, 2)\n",
    "bigramModel = defaultdict(Counter)\n",
    "total = float(len(tokens) - 1)\n",
    "for t1, t2 in myTokenBigrams:\n",
    "    bigramModel[t1][t2] += 1\n",
    "for a in bigramModel:\n",
    "    for b in bigramModel[a]:\n",
    "        bigramModel[a][b] = bigramModel[a][b] / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now look up the continuation of \"white\" with the likelihood of the continuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'rose': 0.00020983056182132927, 'gold': 0.00020983056182132927, 'foam': 7.868646068299847e-05, 'as': 7.868646068299847e-05, 'hands': 5.245764045533232e-05, 'feet': 5.245764045533232e-05, 'girl': 2.622882022766616e-05, 'glare': 2.622882022766616e-05, 'blossoms': 2.622882022766616e-05, 'velvet': 2.622882022766616e-05, 'rose-tree': 2.622882022766616e-05, 'snow-wreaths': 2.622882022766616e-05, 'mule': 2.622882022766616e-05, 'berries': 2.622882022766616e-05, 'statues': 2.622882022766616e-05, 'ceiling': 2.622882022766616e-05, 'petal': 2.622882022766616e-05, 'stars': 2.622882022766616e-05, 'ivory': 2.622882022766616e-05, 'hand': 2.622882022766616e-05, 'teeth': 2.622882022766616e-05, 'arms': 2.622882022766616e-05, 'rocks': 2.622882022766616e-05, 'doves': 2.622882022766616e-05, 'smiling': 2.622882022766616e-05, 'grapes': 2.622882022766616e-05, 'house': 2.622882022766616e-05, 'alabaster': 2.622882022766616e-05, 'leather': 2.622882022766616e-05, 'pigeons': 2.622882022766616e-05, 'peacocks': 2.622882022766616e-05, 'claws': 2.622882022766616e-05, 'flowers': 2.622882022766616e-05, 'shroud': 2.622882022766616e-05, 'snow': 2.622882022766616e-05, 'and': 2.622882022766616e-05})\n"
     ]
    }
   ],
   "source": [
    "print(bigramModel['white'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now generate a trigram frequency profile and relativize the frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTokenTrigrams = nltk.ngrams(tokens, 3)\n",
    "trigramModel = defaultdict(Counter)\n",
    "total = float(len(tokens) - 2)\n",
    "for t1, t2, t3 in myTokenTrigrams:\n",
    "    trigramModel[(t1, t2)][t3] += 1\n",
    "for a in trigramModel:\n",
    "    for b in trigramModel[a]:\n",
    "        trigramModel[a][b] = trigramModel[a][b] / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now look up the continuation of a word sequence \"white rose\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({',': 0.00013114754098360657, '.': 2.622950819672131e-05, 'in': 2.622950819672131e-05, 'to': 2.622950819672131e-05})\n"
     ]
    }
   ],
   "source": [
    "print(trigramModel[('white', 'rose')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following loop we will set a start word and generate a continuation of 20 words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', 'his']\n",
      "['in', 'his', 'beautiful']\n",
      "['in', 'his', 'beautiful', 'chamber']\n",
      "['in', 'his', 'beautiful', 'chamber', '.']\n",
      "['in', 'his', 'beautiful', 'chamber', '.', 'his']\n",
      "['in', 'his', 'beautiful', 'chamber', '.', 'his', 'courtiers']\n",
      "['in', 'his', 'beautiful', 'chamber', '.', 'his', 'courtiers', 'had']\n",
      "['in', 'his', 'beautiful', 'chamber', '.', 'his', 'courtiers', 'had', 'all']\n",
      "['in', 'his', 'beautiful', 'chamber', '.', 'his', 'courtiers', 'had', 'all', 'taken']\n",
      "['in', 'his', 'beautiful', 'chamber', '.', 'his', 'courtiers', 'had', 'all', 'taken', 'their']\n",
      "['in', 'his', 'beautiful', 'chamber', '.', 'his', 'courtiers', 'had', 'all', 'taken', 'their', 'leave']\n"
     ]
    }
   ],
   "source": [
    "state = ['in']\n",
    "bigrams = list(bigramModel[state[-1]].items())\n",
    "sorted(bigrams, key=lambda x: x[1])\n",
    "state.append(bigrams[0][0])\n",
    "print(state)\n",
    "for n in range(10):\n",
    "    continuation = list(trigramModel[tuple(state[-2:])].items())\n",
    "    sorted(continuation, key=lambda x: x[1])\n",
    "    state.append(continuation[0][0])\n",
    "    print(state)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(C) 2024 by [Damir Cavar](http://damir.cavar.me/) <<dcavar@iu.edu>>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "1e28a5307a9b5c2fbeb0b263581f1cf3bfba9739188743f6a231f74c7de58892"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
